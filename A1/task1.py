# -*- coding: utf-8 -*-
"""IDL1Task1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KkH4FB4CalLV_Ayz6vU3fMXWpaeQS5ls
"""

import tensorflow as tf
from tensorflow import keras
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten
from keras import backend as K
from functools import partial
DefaultConv2D = partial(keras.layers.Conv2D,
                        kernel_size=3, activation='relu', padding="SAME")


# layers, dropout+-, aantal nodes/laag
# LM experiment regularisatie + learning rate + loss + optimizer
# minder layers + optimizers + regularizer => loopje
# training time?
# MVP?

class MLP:
    def __init__(self, CIFAR, adam_optimizer):
        if adam_optimizer:
          self.optimize = 'adam'
        else:
          self.optimize = 'sgd'

        self.model = keras.models.Sequential()
        if CIFAR:
          self.model.add(keras.layers.Flatten(input_shape=[32,32,3]))
        else:
          self.model.add(keras.layers.Flatten(input_shape=[28,28,1]))
        self.model.add(keras.layers.Dense(300, activation="relu"))
        self.model.add(keras.layers.Dense(100, activation="relu"))
        self.model.add(keras.layers.Dense(10, activation="softmax"))

    def train(self,X_train, y_train, X_test, y_test, X_valid, y_valid):
        self.model.compile(loss= 'sparse_categorical_crossentropy', optimizer=self.optimize, metrics=["accuracy"])   # optimizer = keras.optimizers.SGD(lr=0.01)
        self.history = self.model.fit(X_train, y_train, epochs = 30, validation_data=(X_valid, y_valid))          # class_weight=class_weight

    def figure(self):
        pd.DataFrame(self.history.history).plot(figsize=(8,5))
        plt.grid(True)
        plt.gca().set_ylim(0,1)
        plt.show()

class CNN:
    def __init__(self, CIFAR, omit_layer, adam_optimizer, omit_dropout):
        if CIFAR:
            ishape = [32,32,3]
        else:
            ishape = [28,28,1]
        if adam_optimizer:
            self.optimize = 'adam'
        else:
            self.optimize = 'sgd'

        if not omit_layer:
            self.model = model = keras.models.Sequential([
                DefaultConv2D(filters=64, kernel_size=7, input_shape=[28, 28, 1]),
                keras.layers.MaxPooling2D(pool_size=2),
                DefaultConv2D(filters=128),
                DefaultConv2D(filters=128),
                keras.layers.MaxPooling2D(pool_size=2),
                DefaultConv2D(filters=256),
                DefaultConv2D(filters=256),
                keras.layers.MaxPooling2D(pool_size=2),
                keras.layers.Flatten(),
                keras.layers.Dense(units=128, activation='relu'),
            ])
        else:
            self.model = model = keras.models.Sequential([
                DefaultConv2D(filters=64, kernel_size=7, input_shape=[28, 28, 1]),
                keras.layers.MaxPooling2D(pool_size=2),
                DefaultConv2D(filters=128),
                keras.layers.MaxPooling2D(pool_size=2),
                DefaultConv2D(filters=256),
                keras.layers.MaxPooling2D(pool_size=2),
                keras.layers.Flatten(),
                keras.layers.Dense(units=128, activation='relu'),
            ])

        if not omit_dropout:
            self.model.add(keras.layers.Dropout(0.5))
        self.model.add(keras.layers.Dense(units=64, activation='relu'))
        if not omit_dropout:
            self.model.add(keras.layers.Dropout(0.5))
        self.model.add(keras.layers.Dense(units=10, activation='softmax'))

        self.filename = 'test'

    def printf(self, input):
        with open(self.filename, 'a') as f:
            print(input, file=f)

    def train(self,X_train, y_train, X_test, y_test, X_valid, y_valid):
        self.model.compile(loss= 'sparse_categorical_crossentropy', optimizer=self.optimize, metrics=["accuracy"])   # optimizer = keras.optimizers.SGD(lr=0.01) => batch norm / adam
        self.history = self.model.fit(X_train, y_train, epochs = 30, validation_data=(X_valid, y_valid))          # class_weight=class_weight

    def figure(self):
        pd.DataFrame(self.history.history).plot(figsize=(8,5))
        plt.grid(True)
        plt.gca().set_ylim(0,1)
        plt.show()

def prep_data(CIFAR):
    if not CIFAR:
        (X_train_full, y_train_full), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()
        X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:]/255.0
        y_valid, y_train = y_train_full[:5000], y_train_full[5000:]
        X_test = X_test / 255.0
        # class_names = ["T-shirt/top", "Trouser", "Pullover", "Dress", "Coat", "Sandal", "Shirt", "Sneaker", "Bag", "Ankle_boot"]
        return X_train, y_train, X_test, y_test, X_valid, y_valid
    else:
        (X_train_full, y_train_full), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()
        assert X_train_full.shape == (50000, 32, 32, 3)
        assert X_test.shape == (10000, 32, 32, 3)
        assert y_train_full.shape == (50000, 1)
        assert y_test.shape == (10000, 1)
        X_valid, X_train = X_train_full[:10000] / 255.0, X_train_full[10000:]/255.0
        y_valid, y_train = y_train_full[:10000], y_train_full[10000:]
        X_test = X_test / 255.0
        return X_train, y_train, X_test, y_test, X_valid, y_valid

# Compare different configurations for MNIST
X_train, y_train, X_test, y_test, X_valid, y_valid = prep_data(False)

for adam in [True, False]:
    myMLP = MLP(False, adam)
    myMLP.train(X_train, y_train, X_test, y_test, X_valid, y_valid)
    print("MLP with adam_optimizer = ", adam, " (else SGD)")
    myMLP.figure()
    for olayer in [True, False]:
        for odropout in [True, False]:
            myCNN = CNN(False, olayer, adam, odropout)
            myCNN.train(X_train, y_train, X_test, y_test, X_valid, y_valid)
            print("CNN with adam_optimizer = ", adam, " (else SGD), omit_layer ", olayer, " and omit_dropout= ", odropout)
            myCNN.figure()

# Apply optimal configurations to CIFAR
X_train, y_train, X_test, y_test, X_valid, y_valid = prep_data(False)

myCNN1 = CNN(True, True, False, True)
myCNN1.train(X_train, y_train, X_test, y_test, X_valid, y_valid)
print("CNN with SGD, 3 convolutional layers and no drop-out layers")
myCNN1.figure()

myCNN2 = CNN(True, True, False, False)
myCNN2.train(X_train, y_train, X_test, y_test, X_valid, y_valid)
print("CNN with SGD, 3 convolutional layers and 2 drop-out layers")
myCNN2.figure()

myCNN3 = CNN(True, False, False, False)
myCNN3.train(X_train, y_train, X_test, y_test, X_valid, y_valid)
print("CNN with SGD, 5 convolutional layers and 2 drop-out layers")
myCNN3.figure()