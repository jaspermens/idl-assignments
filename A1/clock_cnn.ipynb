{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten, BatchNormalization\nfrom keras import backend as K\n\n\n# DATASET_PREFIX = 'drive/MyDrive/idl/datasets/'\n\nDATASET_PREFIX = '/kaggle/input/clock-images/'\nlabels = np.load(DATASET_PREFIX + 'labels.npy')\nimages = np.load(DATASET_PREFIX + 'images.npy')","metadata":{"execution":{"iopub.status.busy":"2023-10-20T15:51:20.360388Z","iopub.execute_input":"2023-10-20T15:51:20.360727Z","iopub.status.idle":"2023-10-20T15:51:31.789396Z","shell.execute_reply.started":"2023-10-20T15:51:20.360699Z","shell.execute_reply":"2023-10-20T15:51:31.788562Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"class clock_CNN:\n    def __init__(self, images, labels,\n                num_classes=12,\n                batch_size=128,\n                num_epochs=20,\n                ):\n        self.num_classes = num_classes\n        self.batch_size = batch_size\n        self.num_epochs = num_epochs\n        self.image_shape = (150, 150, 1)\n        self.filename = 'test'\n\n        self.prep_data(images, labels)\n        self.build_model()\n\n\n    def build_model(self):\n        self.model = keras.models.Sequential([        \n            Conv2D(64, kernel_size=15, strides=4, activation='relu', input_shape=self.image_shape),\n            MaxPooling2D(pool_size=4, strides=4),\n            BatchNormalization(),\n#             Conv2D(64, kernel_size=3, strides=1, activation='relu'),\n#             MaxPooling2D(pool_size=2, strides=2),\n#             BatchNormalization(),\n            Conv2D(16, kernel_size=3, strides=1, activation='relu'),\n            MaxPooling2D(pool_size=2, strides=2),\n            BatchNormalization(),\n            Flatten(),\n            Dropout(0.2),\n            Dense(64, activation='relu'),\n            Dropout(0.2),\n            Dense(128, activation='relu'),\n            Dense(self.num_classes, activation='softmax'),\n        ])\n\n        self.model.summary()\n        \n    def convert_labels(self,labels):\n        \"\"\"\n        Converts tuple labels to integers\n        \"\"\"\n        return tf.math.floor((labels[:,0] + labels[:,1]/60)/12 * self.num_classes)\n        # return 2*labels[:,0] + labels[:,1]//30\n\n    def prep_data(self, X_full, y_full):\n        validation_fraction = 0.1\n        test_fraction = 0.15\n        \n        num_validation = int(validation_fraction * len(y_full))\n        num_testing = int(test_fraction * len(y_full))\n        num_train = len(y_full) - num_validation - num_testing\n        \n        rng = np.random.default_rng(seed=10)\n        shuffled_indices = rng.permutation(len(labels))\n        y_full = y_full[shuffled_indices]\n        X_full = X_full[shuffled_indices]\n\n        y_full = self.convert_labels(y_full)\n        y_full = keras.utils.to_categorical(y_full, num_classes = self.num_classes)\n\n        X_full = X_full.reshape(len(X_full),*self.image_shape)/255\n\n        X_train, X_valid, X_test = X_full[:num_train], X_full[num_train:num_train+num_validation], X_full[num_train+num_validation:]\n        y_train, y_valid, y_test = y_full[:num_train], y_full[num_train:num_train+num_validation], y_full[num_train+num_validation:]\n\n        self.train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(self.batch_size)\n        self.test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(self.batch_size)\n        self.valid_dataset = tf.data.Dataset.from_tensor_slices((X_valid, y_valid)).batch(self.batch_size)\n\n    def cyclic_loss(self, y_true, y_pred):\n        linear_errors = tf.math.abs(y_true - y_pred)\n        errors = tf.minimum(self.num_classes - linear_errors, linear_errors)\n        # mean_error = tf.reduce_mean(tf.math.pow(errors,3), axis=0)\n        mean_error = tf.reduce_mean(errors, axis=0)\n        return mean_error\n\n    def mean_deviation_minutes(self, y_true, y_pred):\n        \"returns mean error in minutes\"\n        y_pred = tf.cast(tf.math.argmax(y_pred, axis=-1), tf.float32)\n        y_true = tf.cast(tf.math.argmax(y_true, axis=-1), tf.float32)\n\n        linear_errors = tf.math.abs(y_true - y_pred)\n        errors = tf.minimum(self.num_classes - linear_errors, linear_errors)\n        \n        mean_error = tf.reduce_mean(errors, axis=0) / self.num_classes * 720\n        return mean_error\n    \n    def train_model(self):\n        self.model.compile(\n                loss='categorical_crossentropy',\n                optimizer=keras.optimizers.Nadam(learning_rate=.001, beta_1=0.9, beta_2=0.999),\n                metrics=['accuracy', self.mean_deviation_minutes],\n        )\n        self.history = self.model.fit(self.train_dataset,\n                                      epochs=self.num_epochs,\n                                      validation_data=self.valid_dataset,\n                                      batch_size=self.batch_size,\n                                      )\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-20T16:31:26.874515Z","iopub.execute_input":"2023-10-20T16:31:26.874910Z","iopub.status.idle":"2023-10-20T16:31:26.890693Z","shell.execute_reply.started":"2023-10-20T16:31:26.874879Z","shell.execute_reply":"2023-10-20T16:31:26.889835Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"myCNN = clock_CNN(images, labels, num_classes=12, batch_size=128, num_epochs=20)\nmyCNN.train_model()","metadata":{"execution":{"iopub.status.busy":"2023-10-20T16:31:28.481800Z","iopub.execute_input":"2023-10-20T16:31:28.482675Z","iopub.status.idle":"2023-10-20T16:32:24.324306Z","shell.execute_reply.started":"2023-10-20T16:31:28.482646Z","shell.execute_reply":"2023-10-20T16:32:24.323389Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"Model: \"sequential_5\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d_10 (Conv2D)          (None, 34, 34, 64)        14464     \n                                                                 \n max_pooling2d_10 (MaxPoolin  (None, 8, 8, 64)         0         \n g2D)                                                            \n                                                                 \n batch_normalization_10 (Bat  (None, 8, 8, 64)         256       \n chNormalization)                                                \n                                                                 \n conv2d_11 (Conv2D)          (None, 6, 6, 16)          9232      \n                                                                 \n max_pooling2d_11 (MaxPoolin  (None, 3, 3, 16)         0         \n g2D)                                                            \n                                                                 \n batch_normalization_11 (Bat  (None, 3, 3, 16)         64        \n chNormalization)                                                \n                                                                 \n flatten_5 (Flatten)         (None, 144)               0         \n                                                                 \n dropout_10 (Dropout)        (None, 144)               0         \n                                                                 \n dense_15 (Dense)            (None, 64)                9280      \n                                                                 \n dropout_11 (Dropout)        (None, 64)                0         \n                                                                 \n dense_16 (Dense)            (None, 128)               8320      \n                                                                 \n dense_17 (Dense)            (None, 12)                1548      \n                                                                 \n=================================================================\nTotal params: 43,164\nTrainable params: 43,004\nNon-trainable params: 160\n_________________________________________________________________\nEpoch 1/20\n106/106 [==============================] - 6s 24ms/step - loss: 2.5150 - accuracy: 0.0870 - common_sense_accuracy: 175.5551 - val_loss: 2.4853 - val_accuracy: 0.0956 - val_common_sense_accuracy: 177.9375\nEpoch 2/20\n106/106 [==============================] - 2s 19ms/step - loss: 2.4534 - accuracy: 0.1046 - common_sense_accuracy: 159.9375 - val_loss: 2.4827 - val_accuracy: 0.1133 - val_common_sense_accuracy: 159.2188\nEpoch 3/20\n106/106 [==============================] - 2s 22ms/step - loss: 2.2562 - accuracy: 0.1684 - common_sense_accuracy: 122.8821 - val_loss: 2.4537 - val_accuracy: 0.1333 - val_common_sense_accuracy: 144.2500\nEpoch 4/20\n106/106 [==============================] - 2s 20ms/step - loss: 1.9974 - accuracy: 0.2251 - common_sense_accuracy: 93.4593 - val_loss: 2.1601 - val_accuracy: 0.1961 - val_common_sense_accuracy: 102.8438\nEpoch 5/20\n106/106 [==============================] - 2s 19ms/step - loss: 1.8006 - accuracy: 0.2799 - common_sense_accuracy: 76.8945 - val_loss: 1.8475 - val_accuracy: 0.2556 - val_common_sense_accuracy: 82.7188\nEpoch 6/20\n106/106 [==============================] - 2s 19ms/step - loss: 1.6181 - accuracy: 0.3395 - common_sense_accuracy: 64.4319 - val_loss: 1.7513 - val_accuracy: 0.3006 - val_common_sense_accuracy: 72.3438\nEpoch 7/20\n106/106 [==============================] - 2s 20ms/step - loss: 1.4672 - accuracy: 0.4044 - common_sense_accuracy: 54.7833 - val_loss: 1.5153 - val_accuracy: 0.3756 - val_common_sense_accuracy: 57.1875\nEpoch 8/20\n106/106 [==============================] - 2s 20ms/step - loss: 1.3769 - accuracy: 0.4381 - common_sense_accuracy: 49.3496 - val_loss: 1.5227 - val_accuracy: 0.3706 - val_common_sense_accuracy: 61.7812\nEpoch 9/20\n106/106 [==============================] - 2s 19ms/step - loss: 1.2779 - accuracy: 0.4730 - common_sense_accuracy: 44.8933 - val_loss: 1.6850 - val_accuracy: 0.3400 - val_common_sense_accuracy: 60.5625\nEpoch 10/20\n106/106 [==============================] - 2s 19ms/step - loss: 1.2016 - accuracy: 0.5013 - common_sense_accuracy: 40.9938 - val_loss: 1.3013 - val_accuracy: 0.4656 - val_common_sense_accuracy: 47.2500\nEpoch 11/20\n106/106 [==============================] - 2s 19ms/step - loss: 1.1372 - accuracy: 0.5318 - common_sense_accuracy: 38.6377 - val_loss: 1.7165 - val_accuracy: 0.3922 - val_common_sense_accuracy: 60.4375\nEpoch 12/20\n106/106 [==============================] - 2s 19ms/step - loss: 1.0980 - accuracy: 0.5559 - common_sense_accuracy: 36.3382 - val_loss: 1.2973 - val_accuracy: 0.4606 - val_common_sense_accuracy: 41.4688\nEpoch 13/20\n106/106 [==============================] - 2s 19ms/step - loss: 1.0573 - accuracy: 0.5653 - common_sense_accuracy: 35.1669 - val_loss: 1.7074 - val_accuracy: 0.3633 - val_common_sense_accuracy: 53.0625\nEpoch 14/20\n106/106 [==============================] - 2s 19ms/step - loss: 1.0212 - accuracy: 0.5825 - common_sense_accuracy: 33.3679 - val_loss: 1.5010 - val_accuracy: 0.4328 - val_common_sense_accuracy: 53.3750\nEpoch 15/20\n106/106 [==============================] - 2s 19ms/step - loss: 0.9910 - accuracy: 0.5957 - common_sense_accuracy: 31.9163 - val_loss: 1.4342 - val_accuracy: 0.4433 - val_common_sense_accuracy: 48.3438\nEpoch 16/20\n106/106 [==============================] - 2s 19ms/step - loss: 0.9571 - accuracy: 0.6090 - common_sense_accuracy: 30.8665 - val_loss: 0.8936 - val_accuracy: 0.6328 - val_common_sense_accuracy: 28.2812\nEpoch 17/20\n106/106 [==============================] - 2s 19ms/step - loss: 0.9357 - accuracy: 0.6169 - common_sense_accuracy: 30.1860 - val_loss: 0.9304 - val_accuracy: 0.6150 - val_common_sense_accuracy: 28.9062\nEpoch 18/20\n106/106 [==============================] - 2s 19ms/step - loss: 0.9139 - accuracy: 0.6249 - common_sense_accuracy: 29.2064 - val_loss: 0.9716 - val_accuracy: 0.6033 - val_common_sense_accuracy: 28.7500\nEpoch 19/20\n106/106 [==============================] - 2s 19ms/step - loss: 0.8806 - accuracy: 0.6418 - common_sense_accuracy: 27.5666 - val_loss: 1.1991 - val_accuracy: 0.4806 - val_common_sense_accuracy: 37.0312\nEpoch 20/20\n106/106 [==============================] - 2s 18ms/step - loss: 0.8673 - accuracy: 0.6456 - common_sense_accuracy: 27.2456 - val_loss: 1.2101 - val_accuracy: 0.5144 - val_common_sense_accuracy: 36.0312\n","output_type":"stream"}]},{"cell_type":"code","source":"myCNN.model.evaluate(myCNN.test_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-10-20T16:34:56.240347Z","iopub.execute_input":"2023-10-20T16:34:56.240702Z","iopub.status.idle":"2023-10-20T16:34:56.979685Z","shell.execute_reply.started":"2023-10-20T16:34:56.240673Z","shell.execute_reply":"2023-10-20T16:34:56.978851Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"22/22 [==============================] - 1s 13ms/step - loss: 1.2011 - accuracy: 0.5163 - common_sense_accuracy: 37.3580\n","output_type":"stream"},{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"[1.2011046409606934, 0.5162962675094604, 37.35795593261719]"},"metadata":{}}]},{"cell_type":"code","source":"subset = myCNN.test_dataset.take(1)\noutput = myCNN.model.predict(subset)\ny_pred = tf.math.argmax(output, axis=-1)\n\ntruelabels = list(subset.as_numpy_iterator())[0][1]\ny_true = tf.math.argmax(truelabels, axis=-1)\n\nprint(tf.math.abs(y_true - y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-10-20T16:34:18.411885Z","iopub.execute_input":"2023-10-20T16:34:18.412249Z","iopub.status.idle":"2023-10-20T16:34:18.985886Z","shell.execute_reply.started":"2023-10-20T16:34:18.412220Z","shell.execute_reply":"2023-10-20T16:34:18.984950Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 1s 536ms/step\ntf.Tensor(\n[ 0  0  1  1  0  7  0  1  1  0  1  1  0  1  0  0  0  1 11  0  2  8  1  0\n  0  1  0  0 11 11  1  0  0  1  0  1  0  1  1  1  1  1  1  1  1  0  1  1\n  0  0  1  1  1  0  0  1  0  0  0  0  9  0  1  1  0  1  1  1  1  5  6  0\n  1  0  1  1  1 11 11  1  1  1  0  9  0  0  0  0  0 11  0  0  0  0  0  1\n  0 11  0  1  0  1  0  0  1  0  1  0 11  0  0  1  1  2  1  1  1  0  1 11\n  0  1  0  0  0  1  1  0], shape=(128,), dtype=int64)\n","output_type":"stream"}]},{"cell_type":"code","source":"def common_sense_accuracy(y_true, y_pred):\n    \"returns mean error in minutes\"\n    num_classes = 12\n    print(y_pred)\n    print(y_true)\n    y_pred = tf.cast(y_pred, tf.float32)\n    y_true = tf.cast(y_true, tf.float32)\n    linear_errors = tf.math.abs(y_true - y_pred)\n    print(linear_errors)\n    errors = tf.minimum(num_classes - linear_errors, linear_errors)\n    print(errors)\n    mean_error = tf.reduce_mean(errors, axis=0)/num_classes*720\n    return mean_error\n\nprint(common_sense_accuracy(y_true, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-10-20T16:34:20.161524Z","iopub.execute_input":"2023-10-20T16:34:20.161893Z","iopub.status.idle":"2023-10-20T16:34:20.175000Z","shell.execute_reply.started":"2023-10-20T16:34:20.161864Z","shell.execute_reply":"2023-10-20T16:34:20.173870Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"tf.Tensor(\n[ 1  1  2 10 11 11  1  2  2  6  8  3  0  2  9  5  9  2  0  6  9 10  0 11\n  2  1  0  8  0  0  4  7  0  4  1  1  0  7 11  4  8  9  9 11  7  2  3  3\n  0 11 10  5  6  1  5  3  4 11  9  5  9  5  4  5 11 10  5  5  3  7 10  7\n  2  4  6  3  3  0  0  2  4  8  6  9  0  9 11  7  4  0  1  3  0  1 11  1\n  7 11 11  8  7  6 11  2  5  7  8 10 11  1  3  2  8  3  9  2  9  0  7 11\n  2 11  0  8  3  4 11  1], shape=(128,), dtype=int64)\ntf.Tensor(\n[ 1  1  1  9 11  4  1  3  3  6  9  2  0  1  9  5  9  3 11  6 11  2  1 11\n  2  2  0  8 11 11  3  7  0  3  1  2  0  8 10  3  7  8 10 10  8  2  2  2\n  0 11  9  6  7  1  5  4  4 11  9  5  0  5  3  6 11 11  6  6  4  2  4  7\n  3  4  7  4  4 11 11  1  3  7  6  0  0  9 11  7  4 11  1  3  0  1 11  2\n  7  0 11  9  7  5 11  2  4  7  9 10  0  1  3  1  9  5  8  1  8  0  6  0\n  2 10  0  8  3  3 10  1], shape=(128,), dtype=int64)\ntf.Tensor(\n[ 0.  0.  1.  1.  0.  7.  0.  1.  1.  0.  1.  1.  0.  1.  0.  0.  0.  1.\n 11.  0.  2.  8.  1.  0.  0.  1.  0.  0. 11. 11.  1.  0.  0.  1.  0.  1.\n  0.  1.  1.  1.  1.  1.  1.  1.  1.  0.  1.  1.  0.  0.  1.  1.  1.  0.\n  0.  1.  0.  0.  0.  0.  9.  0.  1.  1.  0.  1.  1.  1.  1.  5.  6.  0.\n  1.  0.  1.  1.  1. 11. 11.  1.  1.  1.  0.  9.  0.  0.  0.  0.  0. 11.\n  0.  0.  0.  0.  0.  1.  0. 11.  0.  1.  0.  1.  0.  0.  1.  0.  1.  0.\n 11.  0.  0.  1.  1.  2.  1.  1.  1.  0.  1. 11.  0.  1.  0.  0.  0.  1.\n  1.  0.], shape=(128,), dtype=float32)\ntf.Tensor(\n[0. 0. 1. 1. 0. 5. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 2. 4. 1. 0.\n 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 3. 0. 1. 1. 0. 1. 1. 1. 1. 5. 6. 0.\n 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 3. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.\n 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 2. 1. 1. 1. 0. 1. 1.\n 0. 1. 0. 0. 0. 1. 1. 0.], shape=(128,), dtype=float32)\ntf.Tensor(43.59375, shape=(), dtype=float32)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}