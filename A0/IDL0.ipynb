{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c921af84-8432-4c43-85e4-3ee413d0fa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################ Exercise 1 #################################################\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "traindata = np.loadtxt('~/IDL/train_in.csv', delimiter=',')\n",
    "trainlabels = np.genfromtxt('~/IDL/train_out.csv', delimiter=',')\n",
    "\n",
    "testdata = np.genfromtxt('~/IDL/test_in.csv', delimiter=',')\n",
    "testlabels = np.genfromtxt('~/IDL/test_out.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa172e1-0e96-4893-afcb-1f899848f5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the first 10 images in the dataset\n",
    "\n",
    "images = traindata[:11]\n",
    "labels = trainlabels[:11]\n",
    "fig, axes = plt.subplots(2,5, figsize=[5,2.3], layout='constrained')\n",
    "\n",
    "\n",
    "for im, ax, label in zip(images, axes.reshape(1,10)[0], labels):\n",
    "    ax.imshow(im.reshape(16,16), cmap='binary_r')\n",
    "    ax.grid(False)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    # ax.set_xlabel(int(label))\n",
    "\n",
    "fig.suptitle(\"First 10 images\")\n",
    "plt.savefig(\"reportfigs/firstdigits.pdf\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "75f83044-f579-42fe-b0cb-f58e48186752",
   "metadata": {},
   "source": [
    "########### Exercise 1.1 ##################3\n",
    "centers = np.zeros((10, 256))\n",
    "\n",
    "for digit in range(10):\n",
    "    images = traindata[trainlabels==digit]\n",
    "    center = np.mean(images, axis=0)\n",
    "    centers[digit, :] = center\n",
    "\n",
    "# Plot mean images for each number:\n",
    "fig, axes = plt.subplots(2,5, figsize=[5,2.3], layout='constrained')\n",
    "\n",
    "for im, ax in zip(centers, axes.reshape(1,10)[0]):\n",
    "    ax.imshow(im.reshape(16,16), cmap='binary_r')\n",
    "    ax.grid(False)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "fig.suptitle(\"Mean images for each digit\")\n",
    "plt.savefig(\"reportfigs/meandigits.pdf\")\n",
    "\n",
    "distance_matrix = np.zeros((10,10))\n",
    "for (i,j), _ in np.ndenumerate(distance_matrix):\n",
    "    distance_matrix[i,j] = np.linalg.norm(centers[i] - centers[j])\n",
    "\n",
    "distance_matrix /= np.max(distance_matrix)\n",
    "# print(distance_matrix)\n",
    "fig, ax = plt.subplots(1,1, figsize=[5,5], dpi=150)\n",
    "ax.imshow(distance_matrix, cmap='viridis')\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        text = ax.text(j, i, round(distance_matrix[i, j],2),\n",
    "                       ha=\"center\", va=\"center\", color=\"w\")\n",
    "ax.grid(False)\n",
    "ax.set_xticks(ticks=range(10), labels=range(10))\n",
    "ax.set_yticks(ticks=range(10), labels=range(10))\n",
    "ax.set_title(\"Distance Matrix\")\n",
    "plt.savefig(\"reportfigs/distance_matrix.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd61e74-4b92-462f-ba8d-40a9e7e0d8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Exercise 1.2 ###################\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "print(\"pcaing\")\n",
    "pca = PCA(n_components=2)\n",
    "fit = pca.fit_transform(traindata)\n",
    "print(pca.explained_variance_)\n",
    "\n",
    "fig, (ax_pca, ax_umap, ax_tsne) = plt.subplots(1,3, figsize=[13,4], dpi=150, layout='tight')\n",
    "plt.subplots_adjust(wspace=.1)\n",
    "ax = ax_pca\n",
    "\n",
    "for digit in range(10):\n",
    "    plotfit = fit[trainlabels==digit]\n",
    "    ax.scatter(plotfit[:,0], plotfit[:,1], label=str(digit), )\n",
    "    ax.text(s=str(digit), x=np.mean(plotfit[:,0]), y=np.mean(plotfit[:,1]),  zorder=10)\n",
    "\n",
    "ax.set_title(\"Principal Component Analysis\")\n",
    "\n",
    "\n",
    "import umap\n",
    "print(\"umapping\")\n",
    "\n",
    "ump = umap.UMAP(n_components=2)\n",
    "fit = ump.fit_transform(traindata)\n",
    "ax = ax_umap\n",
    "\n",
    "for digit in range(10):\n",
    "    plotfit = fit[trainlabels==digit]\n",
    "    ax.scatter(plotfit[:,0], plotfit[:,1], label=str(digit), )\n",
    "    ax.text(s=str(digit), x=np.mean(plotfit[:,0]), y=np.mean(plotfit[:,1]),  zorder=10)\n",
    "\n",
    "ax.legend(ncols=2)\n",
    "ax.set_title(\"UMAP\")\n",
    "\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "print(\"tsneing\")\n",
    "tsne = TSNE(n_components=2)\n",
    "fit = tsne.fit_transform(traindata)\n",
    "ax = ax_tsne\n",
    "\n",
    "for digit in range(10):\n",
    "    plotfit = fit[trainlabels==digit]\n",
    "    ax.scatter(plotfit[:,0], plotfit[:,1], label=str(digit), )\n",
    "    ax.text(s=str(digit), x=np.mean(plotfit[:,0]), y=np.mean(plotfit[:,1]),  zorder=10)\n",
    "\n",
    "ax.set_title(\"T-SNE\")\n",
    "plt.savefig(\"reportfigs/dimreduction.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1af8e47-96b0-47a1-880b-cbe72bb4c8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## Exercise 1.3 ######################\n",
    "\n",
    "predictions_nmc = np.zeros_like(testlabels)\n",
    "\n",
    "for i, image in enumerate(testdata):\n",
    "    predictions_nmc[i] = np.argmin([np.linalg.norm(image - center) for center in centers])\n",
    "\n",
    "correct_ratio = np.count_nonzero(testlabels==predictions_nmc)/len(testlabels)\n",
    "print(f\"correct: {correct_ratio:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a78c6a-b771-43e9-b389-926bad6882d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## Exercise 1.4 ######################$\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "def get_ratio(n_neighbors):\n",
    "    nbors = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    nbors.fit(traindata, trainlabels)\n",
    "\n",
    "    predictions = nbors.predict(testdata)\n",
    "\n",
    "    return np.count_nonzero(predictions == testlabels)/len(predictions)\n",
    "\n",
    "\n",
    "for n in range(1,10):\n",
    "    print(f\"{n}: {get_ratio(n_neighbors=n):.2%}\")\n",
    "\n",
    "nbors = KNeighborsClassifier(n_neighbors=1)\n",
    "nbors.fit(traindata, trainlabels)\n",
    "\n",
    "predictions_knn = nbors.predict(testdata)\n",
    "\n",
    "cm_nmc = confusion_matrix(testlabels, predictions_nmc, )\n",
    "cm_knn = confusion_matrix(testlabels, predictions_knn, )\n",
    "\n",
    "dsp = ConfusionMatrixDisplay(cm_nmc)\n",
    "dsp.plot()\n",
    "plt.title(\"Nearest Mean Classifier (test set)\")\n",
    "plt.savefig(\"reportfigs/confusion_nmc.pdf\")\n",
    "\n",
    "dsp = ConfusionMatrixDisplay(cm_knn)\n",
    "dsp.plot()\n",
    "plt.title(\"KNN classifier (test set)\")\n",
    "plt.savefig(\"reportfigs/confusion_knn.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d97e247-8e96-4c4a-968d-392d50d78378",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################### Exercise 2 ####################################################\n",
    "import numpy as np\n",
    "traindata = np.loadtxt('train_in.csv', delimiter=',')\n",
    "trainlabels = np.genfromtxt('train_out.csv', delimiter=',', dtype=int)\n",
    "\n",
    "testdata = np.genfromtxt('test_in.csv', delimiter=',')\n",
    "testlabels = np.genfromtxt('test_out.csv', delimiter=',', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5d027cd-f467-44ad-829d-5adab75d0065",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitPerceptron:\n",
    "    def __init__(self, \n",
    "                 traindata, trainlabels, \n",
    "                 testdata, testlabels, \n",
    "                 random_seed: int = 11,\n",
    "                 learning_rate: float = .1,\n",
    "                 ):\n",
    "        \n",
    "        self.traindata = traindata\n",
    "        self.trainlabels = trainlabels\n",
    "        self.testdata = testdata\n",
    "        self.testlabels = testlabels\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.trainmatrix = np.c_[np.ones((len(self.traindata), 1)), self.traindata]\n",
    "        self.testmatrix = np.c_[np.ones((len(self.testdata), 1)), self.testdata]\n",
    "\n",
    "        np.random.seed(random_seed)\n",
    "        self.weights = np.random.random(size=(257,10))\n",
    "\n",
    "    @property\n",
    "    def output(self) -> np.array:\n",
    "        return self.trainmatrix @ self.weights\n",
    "\n",
    "    @property\n",
    "    def guesses(self) -> np.array:\n",
    "        return np.argmax(self.output, axis=1)\n",
    "    \n",
    "    @property\n",
    "    def fraction_correct(self):\n",
    "        return np.sum(self.guesses == self.trainlabels)/len(self.trainlabels)\n",
    "    \n",
    "    @property\n",
    "    def test_score(self):\n",
    "        test_output = self.testmatrix @ self.weights\n",
    "        test_guesses = np.argmax(test_output, axis=1)\n",
    "        return np.sum(test_guesses == self.testlabels)/len(self.testlabels)\n",
    "\n",
    "    def update_weights(self):\n",
    "        \"\"\"Updates the weights once\"\"\"\n",
    "        if np.allclose(self.guesses, self.trainlabels):\n",
    "            return True\n",
    "\n",
    "        # pick a misclassified image\n",
    "        misclassified_image = np.argwhere(self.guesses != self.trainlabels)[0]\n",
    "        \n",
    "        # just a little bookkeeping for the next step\n",
    "        node_activations = self.output[misclassified_image][0]\n",
    "        correct_digit = self.trainlabels[misclassified_image]\n",
    "        c_i_activation = node_activations[correct_digit]\n",
    "\n",
    "        # select which direction to adjust the weights in for each node\n",
    "        ds = np.zeros((10))\n",
    "        too_high_nodes = node_activations > c_i_activation\n",
    "        ds[too_high_nodes] = -1\n",
    "        ds[correct_digit] = 1\n",
    "\n",
    "        # apply the weight adjustments\n",
    "        for digit, d in enumerate(ds):          \n",
    "            self.weights[:, digit] += d * self.learning_rate * self.trainmatrix[misclassified_image][0]\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Repeatedly updates the weights until convergence on the training set.\"\"\"\n",
    "        epoch = 0\n",
    "        while not self.update_weights():\n",
    "            print(f\"epoch {epoch}: train accuracy {self.fraction_correct:.2%}\", end='\\r')\n",
    "            epoch += 1\n",
    "        print()\n",
    "\n",
    "        print(f\"Test set accuracy: {self.test_score:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d2e509-6117-47c5-8e5b-257140589570",
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron1 = DigitPerceptron(traindata = traindata, \n",
    "                        trainlabels = trainlabels,\n",
    "                        testdata = testdata,\n",
    "                        testlabels = testlabels, \n",
    "                        random_seed=1,\n",
    "                        )\n",
    "\n",
    "perceptron1.train()\n",
    "\n",
    "perceptron2 = DigitPerceptron(traindata = traindata, \n",
    "                        trainlabels = trainlabels,\n",
    "                        testdata = testdata,\n",
    "                        testlabels = testlabels, \n",
    "                        random_seed = 2,\n",
    "                        )\n",
    "\n",
    "perceptron2.train()\n",
    "\n",
    "perceptron3 = DigitPerceptron(traindata = traindata, \n",
    "                        trainlabels = trainlabels,\n",
    "                        testdata = testdata,\n",
    "                        testlabels = testlabels, \n",
    "                        random_seed=3,\n",
    "                        )\n",
    "\n",
    "perceptron3.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1af34676-3ef2-4055-81ce-b439edca26db",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################### Exercise 3 ####################################################\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59ec120e-ca8d-4b42-8860-307b5b9a27be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def actfun(val):                        # Activation functions\n",
    "    if actyp == \"sigmoid\":\n",
    "        return (1/(1+math.exp(-val)))\n",
    "    if actyp == \"tanh\":\n",
    "        return math.tanh(val)\n",
    "    if actyp == \"relu\":\n",
    "        return max(0,val)\n",
    "\n",
    "def deractfun(val):\n",
    "    if actyp == \"sigmoid\":\n",
    "        return val*(1-val)\n",
    "    if actyp == \"tanh\":\n",
    "        return 1-val**2\n",
    "    if actyp == \"relu\":\n",
    "        if val >= 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "def activations(weights, input):        # Calculates activations of hidden and output nodes\n",
    "    net0 = input[0]*weights[0] + input[1]*weights[1] + weights[2]\n",
    "    y0 = actfun(net0)\n",
    "    net1 = input[0]*weights[3] + input[1]*weights[4] + weights[5]\n",
    "    y1 = actfun(net1)\n",
    "    net = y0*weights[6] + y1*weights[7] + weights[8]\n",
    "    y = actfun(net)\n",
    "    return(y0, y1, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1902990f-4187-47fc-8524-d3e841b71868",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Exercise 3.1 ##############################\n",
    "def xor_net(weights, input):            # Returns value of output node\n",
    "    act = activations(weights, input)\n",
    "    return act[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e6d7dca-0a73-4e60-bd0c-9073b10ed0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## Exercise 3.2 #########################\n",
    "def mse(weights, inputs, targets):      # Calculates MSE + number of misclassified inputs\n",
    "    tot, misit = 0, 0\n",
    "    for index, input in enumerate(inputs):\n",
    "        tot += (1/2)*(xor_net(weights, input)-targets[index])**2\n",
    "        if (targets[index] == 0) and (xor_net(weights,input) > 0.5):    # Outcome > 0.5 is considered 1\n",
    "            misit += 1\n",
    "        if (targets[index] == 1) and (xor_net(weights,input) <= 0.5):   # Outcome <= 0.5 is considered 0\n",
    "            misit += 1\n",
    "    return tot, misit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bea36393-a217-4e66-9fe4-07f5a47de439",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## Exercise 3.3 ###########################\n",
    "def grdmse(weights, input, target):    # Output length == input vector weights\n",
    "    act = activations(weights, input)\n",
    "    # pw = (act[2]-target)*act[2]*(1-act[2])\n",
    "    pw = (act[2]-target)*deractfun(act[2]) \n",
    "    # pu = (act[2]-target)*act[2]*(1-act[2])*act[0]*(1-act[0])*weights[6]\n",
    "    pu = (act[2]-target)*deractfun(act[2])*deractfun(act[0])*weights[6]\n",
    "    # pv = (act[2]-target)*act[2]*(1-act[2])*act[1]*(1-act[1])*weights[7]\n",
    "    pv = (act[2]-target)*deractfun(act[2])*deractfun(act[1])*weights[7]\n",
    "    return [pu*input[0], pu*input[1], pu, pv*input[0], pv*input[1], pv, pw*act[0], pw*act[1], pw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8aa5ca9-eb54-45d5-bf49-59aa051f746e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights before training:  [-0.7173776388292983, 0.6640639872486238, -0.8912583883523792, 0.7116046005736738, 0.3402046790906432, -0.24165280660248967, -0.38484453168522825, -0.08400670571784086, -0.8616370917508687]\n",
      "Training complete\n",
      "Iterations:  150  MSE:  0.07805818266367377  Misclassified:  0\n",
      "Weights after training:  [-7.242681598610078, 5.232293016092222, -3.7857695182142326, -2.931118764466326, 4.663871248254791, 0.5454989606361624, 5.799674411534954, -4.087413159457457, 1.3351470692432592]\n"
     ]
    }
   ],
   "source": [
    "################## Exercise 3.4 ###################################\n",
    "def initweights():                      # Random weights initialization\n",
    "    if inityp == 'uniform':\n",
    "        return [random.uniform(-1,1) for i in range(9)]\n",
    "    if inityp == 'normal':\n",
    "        return [np.random.normal(0,0.2) for i in range(9)]\n",
    "\n",
    "def gradec(weights, inputs, targets):                       # Gradient descent \n",
    "    it = 0\n",
    "    curmse, misit = mse(weights, inputs, targets)           # Calculate MSE and #misclassified items\n",
    "    while (curmse > traincut) and (it < trainit):           \n",
    "        it += 1\n",
    "        for index, input in enumerate(inputs):\n",
    "            tgrad = grdmse(weights, input, targets[index])  # Gradient of MSE\n",
    "            for index1 in range(len(weights)):\n",
    "                weights[index1] -= eta * tgrad[index1]      # Update rule\n",
    "        curmse, misit = mse(weights, inputs, targets)\n",
    "    print(\"Training complete\")\n",
    "    print(\"Iterations: \", it, \" MSE: \", curmse, \" Misclassified: \", misit)\n",
    "    print(\"Weights after training: \", weights)\n",
    "    return\n",
    "\n",
    "eta = 10                                   # Learning rate\n",
    "actyp = \"sigmoid\"                           # Activation function type: sigmoid, tanh or relu\n",
    "inityp = \"uniform\"                          # Initialization strategy: normal or uniform\n",
    "typ = \"training\"                            # Lazy random trial & error or training\n",
    "inputs = [[0,0], [1,0], [0,1], [1,1]]       # Training inputs\n",
    "targets = [0,1,1,0]                         # Training outputs\n",
    "trainit = 1000                              # Maximum number of training iterations\n",
    "traincut = 0.1                              # Upper bound for target MSE\n",
    "\n",
    "if typ == \"lazy\":\n",
    "    for i in range(trainit):\n",
    "        weights = initweights()                         # Weight initialization\n",
    "        curmse, misit = mse(weights, inputs, targets)   # Calculate MSE and #misclassified items\n",
    "        print(\"Iteration \", i,\": MSE = \", curmse, \" Misclassified inputs: \", misit)\n",
    "        if curmse < traincut:\n",
    "            break\n",
    "else:\n",
    "    weights = initweights()                         # Weight initialization\n",
    "    print(\"Weights before training: \", weights)\n",
    "    gradec(weights, inputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e6dd78-cdb2-43aa-b843-7dfefabd86ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afecdea1-238e-4758-bb9e-01571773c90e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1188f54f-0380-4d27-bb96-32c26dfbf755",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
